{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alike-baseball",
   "metadata": {},
   "outputs": [],
   "source": [
    "from twarc import Twarc2, expansions\n",
    "import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prompt-island",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Twarc2(bearer_token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abandoned-ordering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list for the 16 media that will be used in this study \n",
    "media = [\"CNN\", \"nytimes\", \"FoxNews\", \"WSJ\", \"washingtonpost\", \"TIME\", \"ABC\", \"HuffPost\", \"NBCNews\", \"NewYorker\", \"NPR\", \"CBSNews\", \n",
    "         \"business\", \"USATODAY\", \"MSNBC\", \"Newsweek\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "silver-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the company dataset\n",
    "corporation = pd.read_csv (\"fortune500.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "optional-vietnamese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>industry</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>twitter</th>\n",
       "      <th>followers_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>Bentonville, AR</td>\n",
       "      <td>General Merchandisers</td>\n",
       "      <td>AR</td>\n",
       "      <td>Bentonville</td>\n",
       "      <td>Walmart</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Exxon Mobil</td>\n",
       "      <td>Irving, TX</td>\n",
       "      <td>Petroleum Refining</td>\n",
       "      <td>TX</td>\n",
       "      <td>Irving</td>\n",
       "      <td>exxonmobil</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevron</td>\n",
       "      <td>San Ramon, CA</td>\n",
       "      <td>Petroleum Refining</td>\n",
       "      <td>CA</td>\n",
       "      <td>San Ramon</td>\n",
       "      <td>Chevron</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple</td>\n",
       "      <td>Cupertino, CA</td>\n",
       "      <td>Computers, Office Equipment</td>\n",
       "      <td>CA</td>\n",
       "      <td>Cupertino</td>\n",
       "      <td>AppleSupport</td>\n",
       "      <td>1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Motors</td>\n",
       "      <td>Detroit, MI</td>\n",
       "      <td>Motor Vehicles and Parts</td>\n",
       "      <td>MI</td>\n",
       "      <td>Detroit</td>\n",
       "      <td>GM</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          company         location                     industry state  \\\n",
       "0         Walmart  Bentonville, AR        General Merchandisers    AR   \n",
       "1     Exxon Mobil       Irving, TX           Petroleum Refining    TX   \n",
       "2         Chevron    San Ramon, CA           Petroleum Refining    CA   \n",
       "3           Apple    Cupertino, CA  Computers, Office Equipment    CA   \n",
       "4  General Motors      Detroit, MI     Motor Vehicles and Parts    MI   \n",
       "\n",
       "          city       twitter  followers_m  \n",
       "0  Bentonville       Walmart          1.2  \n",
       "1       Irving    exxonmobil          0.3  \n",
       "2    San Ramon       Chevron          0.4  \n",
       "3    Cupertino  AppleSupport          1.4  \n",
       "4      Detroit            GM          0.8  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corporation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabulous-seafood",
   "metadata": {},
   "source": [
    "### Retrieve media tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "vertical-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "company = list(corporation[\"company\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "legitimate-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "considerable-party",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create queries to get media tweets\n",
    "for c in company:\n",
    "    for m in media:\n",
    "        q = f\"{c} from:{m}\"  # only retrieve tweets that include the company names from the media's Twitter account\n",
    "        query.append(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "adaptive-calgary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4720"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "express-baptist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use chunks to handle large file downloading\n",
    "chuncks = [query[x:x+10] for x in range(0, len(query), 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nonprofit-thesaurus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "472"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chuncks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "exact-riding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the start time and end time for the time period you want Tweets from\n",
    "start_time = datetime.datetime(2021, 1, 1, 0, 0, 0, 0, datetime.timezone.utc)\n",
    "end_time = datetime.datetime(2022, 1, 1, 0, 0, 0, 0, datetime.timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "given-caution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading\n",
    "i= 0\n",
    "for chunck in chuncks:\n",
    "    i+=1 \n",
    "    media_posts = pd.DataFrame()\n",
    "    \n",
    "    for q in chunck:\n",
    "        search_results = client.search_all(query=q, start_time=start_time, end_time=end_time, max_results=100)\n",
    "        for page in search_results:\n",
    "            result = expansions.flatten(page)\n",
    "            for tweet in result:\n",
    "                media_posts = media_posts.append(tweet,ignore_index=True)\n",
    "\n",
    "        media_posts.to_json(f'{i}_datafile.jsonl')\n",
    "        time.sleep(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all media tweets together\n",
    "files = glob('media/*.jsonl')\n",
    "media_full = pd.DataFrame()\n",
    "for filename in files:\n",
    "    df = pd.read_json(filename)\n",
    "    media_full = media_full.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-mechanism",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(media_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alien-announcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_full.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "danish-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_full.to_json(\"media.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-birthday",
   "metadata": {},
   "source": [
    "### Retrieve corporate tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "oriental-necklace",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_twitter = list(corporation[\"twitter\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "deluxe-allah",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "295"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cor_twitter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acute-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create queries based on corporate Twitter account, the start time and end time are the same as the media tweets.\n",
    "for c in cor_twitter:\n",
    "    corporate_posts = pd.DataFrame()\n",
    "    search_results = client.search_all(query=f'from:{c} -is:reply', start_time=start_time, end_time=end_time, max_results=100)\n",
    "    for page in search_results:\n",
    "        result = expansions.flatten(page)\n",
    "        for tweet in result:\n",
    "            corporate_posts = corporate_posts.append(tweet,ignore_index=True)\n",
    "\n",
    "    # save the data per corporation\n",
    "    corporate_posts.to_json(f'{c}.jsonl')\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-vulnerability",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all corporate tweets together\n",
    "files = glob('corporation/*.jsonl')\n",
    "cor_full = pd.DataFrame()\n",
    "for filename in files:\n",
    "    df = pd.read_json(filename)\n",
    "    cor_full = cor_full.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cor_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-fitness",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_full.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "cor_full.to_json(\"corporation.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
